# CUDA Disabled
Running this on a CPU will take over 4 hours/epoch, making training impractical. However, inference is still feasible due to the smaller U-Net dimensions, allowing for reasonable processing times.
